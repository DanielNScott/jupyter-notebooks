{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 #\n",
    "\n",
    "**Notes:**\n",
    " - Informally, the \"learning model\" is the hypothesis set and the algorithm used to search that set.\n",
    " - The hypothesis set is essentially a set of functions, i.e. a functional form with unspecified parameters.\n",
    " \n",
    "**Perceptrons:**\n",
    " - The perceptron is essentially a one input layer, one output layer, zero hidden layer neural network model, with a binary output variable.\n",
    " - The ***perceptron learning algorithm*** iteratively moves it's linear classification boundary \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "\n",
    "class perceptron(object):\n",
    "    \"\"\"A perceptron, i.e. a weighted sum of some inputs and a bias:\n",
    "\n",
    "    Fields:\n",
    "        weights: The set of weights in the weighted sum, initialized to zeros.\n",
    "\n",
    "    Methods:\n",
    "        classify: Return the classification (+-1) of an input.\n",
    "    \"\"\"\n",
    "    def __init__(self,input_length):\n",
    "        self.weights = np.zeros(input_length + 1,float)\n",
    "        \n",
    "    def classify(self,vector):\n",
    "        feature_vec = np.insert(vector,1,1)\n",
    "        summation = np.dot(feature_vec, self.weights)\n",
    "        sgn = int(np.sign(summation))\n",
    "\n",
    "        # Avoid sign operator outputing 0.\n",
    "        sgn = sgn if sgn != int(0) else 1\n",
    "\n",
    "        return sgn\n",
    "        \n",
    "my_ptron = perceptron(2)\n",
    "result = my_ptron.classify(np.array([1,1]))\n",
    "print('result: ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn_naive(perceptron, design_array, targets, max_iter):\n",
    "    '''An implementation of the perceptron learning algorithm that learns somewhat inefficiently.'''\n",
    "    \n",
    "    n_vecs = len(design_array)\n",
    "    num_accurate = 0\n",
    "    index = 0\n",
    "    while iteration < max_iter and num_accurate != n_vecs:\n",
    "        feature_vec = design_array[ind]\n",
    "        feature_vec_aug = np.insert(feature_vec,1,1)\n",
    "        \n",
    "        prediction = perceptron.classify(design_array[ind])\n",
    "        \n",
    "        if targets[index] == prediction:\n",
    "            num_accurate = num_accurate + 1\n",
    "        else:\n",
    "            num_accurate = 0\n",
    "            perceptron.weights = perceptron.weights + targets[index]*feature_vec_aug\n",
    "            index = 0\n",
    "                \n",
    "        iteration = iteration + 1\n",
    "    \n",
    "    return perceptron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 1.2 ##\n",
    "Suppose that we use a perceptron to detect spam. Let's say that each email message is represented by the requency of occurence of keywords, and that the output is +1 if the message is considered spam.\n",
    "1. What keywords might end up with a large positive weight in the perceptron?\n",
    "   - Viagra\n",
    "2. How about keywords that will get a negative weight?\n",
    "   - Specific people and places I have relationships with\n",
    "3. What parameter in the perceptron directly affects how many borderline messages end up being classified as spam.\n",
    "   - The bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. 1.3 ##\n",
    "The weight update rule in in the PLA has a nice interpretation that it moves in the direction of classifying x(t) correctly.\n",
    "1. Show that $y(t)\\textbf{w}^T(t)\\textbf{x}^T < 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
